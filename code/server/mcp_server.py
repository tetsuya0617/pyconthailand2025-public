"""
MCP Server for Speech-to-Text and Translation

Provides two tools via Model Context Protocol:
- translate: Translates text to Thai
- stt: Transcribes audio data to text (client records, server transcribes)
"""

import logging
import base64
from pathlib import Path
from pydantic import BaseModel, Field
from mcp.server.fastmcp import FastMCP
from googletrans import Translator
from faster_whisper import WhisperModel

# Reduce log verbosity
logging.basicConfig(level=logging.WARNING)

# Initialize MCP server
mcp = FastMCP("speech-translate")

# Initialize models
whisper_model = WhisperModel("tiny", device="cpu", compute_type="int8")


# ============================================================================
# Translation (Server-side)
# ============================================================================


async def translate_text(text: str, dest: str = "th") -> str:
    """Translate text to target language using Google Translate.

    Args:
        text: The text to translate.
        dest: Target language code. Defaults to "th" (Thai).

    Returns:
        str: The translated text.
    """
    translator = Translator()
    result = await translator.translate(text, dest=dest)
    return result.text


# ============================================================================
# Output Models
# ============================================================================


class TranslateOut(BaseModel):
    translated_text: str = Field(description="Text translated to Thai")


class STTOut(BaseModel):
    transcribed_text: str = Field(description="Transcribed text from audio")


# ============================================================================
# MCP Tools
# ============================================================================
# FastMCP automatically generates tool metadata from function signatures and docstrings.
# No need to manually define metadata like in vendor-specific Function Calling APIs.
#
# What FastMCP auto-generates:
# - name: Extracted from function name (e.g., "translate")
# - description: Full docstring content (including newlines)
# - inputSchema: Generated from type hints and Pydantic models
#   - Type hints (text: str) → {"type": "string"}
#   - Return type (TranslateOut) → Output schema with Pydantic Field descriptions
#
# Example metadata generated by FastMCP for translate():
# {
#   "name": "translate",
#   "description": "Translates the given text to Thai language...",
#   "inputSchema": {
#     "type": "object",
#     "properties": {
#       "text": {"type": "string"}
#     },
#     "required": ["text"]
#   }
# }
#
# This is vendor-neutral! No need to rewrite for Gemini, OpenAI, or Claude.


@mcp.tool()
async def translate(text: str) -> TranslateOut:
    """Translates the given text to Thai language.

    MCP tool for text translation. Automatically registered with @mcp.tool() decorator.

    Args:
        text: The text to translate to Thai.

    Returns:
        TranslateOut: Pydantic model containing the translated text.
            Example: TranslateOut(translated_text="สวัสดี")
    """
    try:
        result = await translate_text(text, dest="th")
        return TranslateOut(translated_text=result)
    except Exception as e:
        return TranslateOut(translated_text=f"Error: {str(e)}")


@mcp.tool()
def stt(audio_base64: str) -> STTOut:
    """Transcribes audio data to text.

    MCP tool for speech-to-text. Automatically registered with @mcp.tool() decorator.

    Args:
        audio_base64: Base64-encoded WAV audio data from client.

    Returns:
        STTOut: Pydantic model containing the transcribed text.
            Example: STTOut(transcribed_text="Hello world")
    """
    try:
        # Decode base64 audio data
        audio_data = base64.b64decode(audio_base64)

        # Save temporarily
        audio_path = Path("/tmp/mcp_server_audio.wav")
        with open(audio_path, "wb") as f:
            f.write(audio_data)

        # Transcribe
        segments, _ = whisper_model.transcribe(str(audio_path))
        text = " ".join([segment.text for segment in segments])

        # Cleanup
        audio_path.unlink(missing_ok=True)

        return STTOut(transcribed_text=text.strip())
    except Exception as e:
        return STTOut(transcribed_text=f"Error: {str(e)}")


if __name__ == "__main__":
    mcp.run()
